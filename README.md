# AML

## Assignment 1
A simple neural network class coded from scratch using just numpy in python. It can be used to create multi-layer perceptron architectures with various activation functions.

Activation functions implemented
1. Sigmoid
2. ReLU
3. Leaky ReLU
4. tanh
5. SoftMax

It implements common regularization techniques:
* Dropout
* Batch Normalization
* L1 - Lasso
* L2 - Ridge

 ADAM optimiser is also implemented
  
 
